names(getModelInfo())
# create sub-models
trainControl <- trainControl(method = "cv",
number = 5,
savePredictions = TRUE,
classProbs = TRUE)
algorithmList <- c('knn', 'glm', 'xgbLinear', 'rf', 'xgbTree')
# set random number
set.seed(1087)
models <- caretList(diabetes ~ .,
data = PimaIndiansDiabetes,
trControl = trainControl,
methodList = algorithmList)
print(models)
# stacking models
stackControl <- trainControl(
method = "cv",
number = 5,
savePredictions = TRUE,
classProbs = TRUE
)
set.seed(1087)
stack.glm <- caretStack(models, method = "glm",
trControl = trainControl)
print(stack.glm)
stackControl <- trainControl(
method = "cv",
number = 5,
savePredictions = TRUE,
classProbs = TRUE
)
set.seed(1087)
stack.glm <- caretStack(models, method = "xgbTree",
trControl = trainControl)
print(stack.glm)
?caretStack
# stacking models
stackControl <- trainControl(
method = "cv",
number = 5,
savePredictions = TRUE,
classProbs = TRUE
)
set.seed(1087)
stack.glm <- caretStack(models, method = "glm",
trControl = trainControl)
print(stack.glm)
# adapted from caret vignette
library(caret)
library(mlbench)
library(pROC)
# load the sonar dataset
data(Sonar)
# random number seed
set.seed(1087)
inTrain <- createDataPartition(y = Sonar$Class,
p = 0.75,
list = FALSE)
training <- Sonar[inTrain, ]
testing  <- Sonar[-inTrain, ]
my_control <- trainControl(
method = "boot",
number = 25,
savePredictions = "final",
classProbs = TRUE,
index = createResample(training$Class, 25),
summaryFunction = twoClassSummary
)
library(rpart)
library(caretEnsemble)
model_list <- caretList(
Class ~ .,
data = training,
trControl = my_control,
methodList = c("glm", "rpart")
)
# Load packages
library(mlbench)
library(caret)
library(caretEnsemble)
# load the Pima Indians Diabetes dataset
data("PimaIndiansDiabetes")
# create sub-models
trainControl <- trainControl(method = "cv",
number = 5,
savePredictions = TRUE,
classProbs = TRUE)
algorithmList <- c('knn', 'glm', 'xgbLinear', 'rf', 'xgbTree')
# set random number
set.seed(1087)
models <- caretList(diabetes ~ .,
data = PimaIndiansDiabetes,
trControl = trainControl,
methodList = algorithmList)
print(models)
# adapted from caret vignette
library(caret)
library(mlbench)
library(pROC)
# load the sonar dataset
data(Sonar)
# random number seed
set.seed(1087)
inTrain <- createDataPartition(y = Sonar$Class,
p = 0.75,
list = FALSE)
training <- Sonar[inTrain, ]
testing  <- Sonar[-inTrain, ]
my_control <- trainControl(
method = "boot",
number = 25,
savePredictions = "final",
classProbs = TRUE,
index = createResample(training$Class, 25),
summaryFunction = twoClassSummary
)
library(rpart)
library(caretEnsemble)
model_list <- caretList(
Class ~ .,
data = training,
trControl = my_control,
methodList = c("glm", "rpart")
)
library("mlbench")
library("randomForest")
library("nnet")
model_list_big <- caretList(
Class ~ .,
data = training,
trControl = my_control,
metric = "ROC",
methodList = c("glm", "rpart"),
tuneList = list(
rf1 = caretModelSpec(method = "rf", tuneGrid = data.frame(.mtry = 2)),
rf2 = caretModelSpec(
method = "rf",
tuneGrid = data.frame(.mtry = 10),
preProcess = "pca"
),
nn = caretModelSpec(
method = "nnet",
tuneLength = 2,
trace = FALSE
)
)
)
print(model_list_big)
modelCor(resamples(model_list))
modelCor(resamples(model_list_big))
# ensemble dataset
greedy_ensemble <- caretEnsemble(
model_list,
metric = "ROC",
trControl = trainControl(
number = 2,
summaryFunction = twoClassSummary,
classProbs = TRUE
)
)
summary(greedy_ensemble)
# ensemble dataset
greedy_ensemble <- caretEnsemble(
model_list_big,
metric = "ROC",
trControl = trainControl(
number = 2,
summaryFunction = twoClassSummary,
classProbs = TRUE
)
)
summary(greedy_ensemble)
# stacking models
stackControl <- trainControl(
method = "cv",
number = 5,
savePredictions = TRUE,
classProbs = TRUE
)
set.seed(1087)
stack.glm <- caretEnsemble(models, method = "glm",
trControl = trainControl)
print(stack.glm)
# stacking models
stackControl <- trainControl(
number = 5,
savePredictions = TRUE,
classProbs = TRUE
)
set.seed(1087)
stack.glm <- caretEnsemble(models,
metric = "ROC",
trControl = trainControl)
print(stack.glm)
# Load packages
library(mlbench)
library(caret)
library(caretEnsemble)
# load the Pima Indians Diabetes dataset
data("PimaIndiansDiabetes")
# create sub-models
trainControl <- trainControl(method = "cv",
number = 5,
savePredictions = TRUE,
classProbs = TRUE)
algorithmList <- c('knn', 'glm', 'xgbLinear', 'rf', 'xgbTree')
# set random number
set.seed(1087)
models <- caretList(diabetes ~ .,
data = PimaIndiansDiabetes,
trControl = trainControl,
methodList = algorithmList)
print(models)
# stacking models
stackControl <- trainControl(
number = 5,
savePredictions = TRUE,
classProbs = TRUE
)
set.seed(1087)
stack.glm <- caretEnsemble(models,
metric = "ROC",
trControl = stackControl)
print(stack.glm)
# create sub-models
trainControl <- trainControl(method = "cv",
number = 5,
savePredictions = TRUE,
classProbs = TRUE)
algorithmList <- c('knn', 'glm', 'xgbLinear', 'rf', 'xgbTree')
# set random number
set.seed(1087)
models <- caretList(diabetes ~ .,
data = PimaIndiansDiabetes,
metric = "ROC",
trControl = trainControl,
methodList = algorithmList)
print(models)
install.packages('h2o')
library(h2o)
localH2O = h2o.init(nthreads=-1)
demo(h2o.kmeans)
# The following two commands remove any previously installed H2O packages for R.
if ("package:h2o" %in% search()) { detach("package:h2o", unload=TRUE) }
if ("h2o" %in% rownames(installed.packages())) { remove.packages("h2o") }
# Next, we download packages that H2O depends on.
pkgs <- c("methods","statmod","stats","graphics","RCurl","jsonlite","tools","utils")
for (pkg in pkgs) {
if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }
}
# Now we download, install and initialize the H2O package for R.
install.packages("h2o", type="source", repos=(c("http://h2o-release.s3.amazonaws.com/h2o/rel-turan/1/R")))
library(h2o)
localH2O = h2o.init(nthreads=-1)
# Finally, let's run a demo to see H2O at work.
demo(h2o.kmeans)
# Goals: ARMA modeling - estimation, diagnostics, forecasting.
# 0. SETUP DATA
rawdata <- c(-0.21,-2.28,-2.71,2.26,-1.11,1.71,2.63,-0.45,-0.11,4.79,5.07,-2.24,6.46,3.82,4.29,-1.47,2.69,7.95,4.46,7.28,3.43,-3.19,-3.14,-1.25,-0.50,2.25,2.77,6.72,9.17,3.73,6.72,6.04,10.62,9.89,8.23,5.37,-0.10,1.40,1.60,3.40,3.80,3.60,4.90,9.60,18.20,20.60,15.20,27.00,15.42,13.31,11.22,12.77,12.43,15.83,11.44,12.32,12.10,12.02,14.41,13.54,11.36,12.97,10.00,7.20,8.74,3.92,8.73,2.19,3.85,1.48,2.28,2.98,4.21,3.85,6.52,8.16,5.36,8.58,7.00,10.57,7.12,7.95,7.05,3.84,4.93,4.30,5.44,3.77,4.71,3.18,0.00,5.25,4.27,5.14,3.53,4.54,4.70,7.40,4.80,6.20,7.29,7.30,8.38,3.83,8.07,4.88,8.17,8.25,6.46,5.96,5.88,5.03,4.99,5.87,6.78,7.43,3.61,4.29,2.97,2.35,2.49,1.56,2.65,2.49,2.85,1.89,3.05,2.27,2.91,3.94,2.34,3.14,4.11,4.12,4.53,7.11,6.17,6.25,7.03,4.13,6.15,6.73,6.99,5.86,4.19,6.38,6.68,6.58,5.75,7.51,6.22,8.22,7.45,8.00,8.29,8.05,8.91,6.83,7.33,8.52,8.62,9.80,10.63,7.70,8.91,7.50,5.88,9.82,8.44,10.92,11.67)
# Make a R timeseries out of the rawdata: specify frequency & startdate
gIIP <- ts(rawdata, frequency=12, start=c(1991,4))
print(gIIP)
plot.ts(gIIP, type="l", col="blue", ylab="IIP Growth (%)", lwd=2,
main="Full data")
grid()
# Based on this, I decide that 4/1995 is the start of the sensible period.
gIIP <- window(gIIP, start=c(1995,4))
print(gIIP)
plot.ts(gIIP, type="l", col="blue", ylab="IIP Growth (%)", lwd=2,
main="Estimation subset")
grid()
# Descriptive statistics about gIIP
mean(gIIP); sd(gIIP); summary(gIIP);
plot(density(gIIP), col="blue", main="(Unconditional) Density of IIP growth")
acf(gIIP)
# 1. ARMA ESTIMATION
m.ar2 <- arima(gIIP, order = c(2,0,0))
print(m.ar2)                       # Print it out
# 2. ARMA DIAGNOSTICS
tsdiag(m.ar2)                      # His pretty picture of diagnostics
## Time series structure in errors
print(Box.test(m.ar2$residuals, lag=12, type="Ljung-Box"));
## Sniff for ARCH
print(Box.test(m.ar2$residuals^2, lag=12, type="Ljung-Box"));
## Eyeball distribution of residuals
plot(density(m.ar2$residuals), col="blue", xlim=c(-8,8),
main=paste("Residuals of AR(2)"))
# 3. FORECASTING
## Make a picture of the residuals
plot.ts(m.ar2$residual, ylab="Innovations", col="blue", lwd=2)
s <- sqrt(m.ar2$sigma2)
abline(h=c(-s,s), lwd=2, col="lightGray")
p <- predict(m.ar2, n.ahead = 12)         # Make 12 predictions.
print(p)
## Watch the forecastability decay away from fat values to 0.
## sd(x) is the naive sigma. p$se is the prediction se.
gain <- 100*(1-p$se/sd(gIIP))
plot.ts(gain, main="Gain in forecast s.d.", ylab="Per cent",
col="blue", lwd=2)
## Make a pretty picture that puts it all together
ts.plot(gIIP, p$pred, p$pred-1.96*p$se, p$pred+1.96*p$se,
gpars=list(lty=c(1,1,2,2), lwd=c(2,2,1,1),
ylab="IIP growth (%)", col=c("blue","red", "red", "red")))
grid()
abline(h=mean(gIIP), lty=2, lwd=2, col="lightGray")
legend(x="bottomleft", cex=0.8, bty="n",
lty=c(1,1,2,2), lwd=c(2,1,1,2),
col=c("blue", "red", "red", "lightGray"),
legend=c("IIP", "AR(2) forecasts", "95% C.I.", "Mean IIP growth"))
a <- gl(2, 4, 8)
b <- gl(2, 2, 8, labels = c("ctrl", "treat"))
s <- gl(2, 1, 8, labels = c("M", "F"))
interaction(a, b)
interaction(a, b, s, sep = ":")
stopifnot(identical(a:s,
interaction(a, s, sep = ":", lex.order = TRUE)),
identical(a:s:b,
interaction(a, s, b, sep = ":", lex.order = TRUE)))
a <- factor(rep(1:3,4), labels="low", "medium", "high")
b <- factor(rep(1:4,3))
levels(strata(b))
levels(strata(a,b,shortlabel=TRUE))
coxph(Surv(futime, fustat) ~ age + strata(rx), data=ovarian)
library(survival)
a <- factor(rep(1:3,4), labels="low", "medium", "high")
b <- factor(rep(1:4,3))
levels(strata(b))
b
levels(strata(a,b,shortlabel=TRUE))
a
a <- factor(rep(1:3,4), labels="low", "medium", "high")
a
shiny::runApp('C:/Users/SURESH/Dropbox/projects/bapm/spring 2016/data mining/project/Movielense')
library(recommenderlab)
data("Movielense")
data(Movielense)
data("MovieLense")
MovieLense100 <- MovieLense[rowCounts(MovieLense)>100,]
train <- MovieLense[1:100]
rec <- Recommender(train, method = "POPULAR")
rec
pre <- predict(rec, MovieLense100[101:102], n = 10)
pre
as(pre, "list")
pre1 <- predict(rec, MovieLense100[101,102], type = "ratings")
as(pre1, "matrix")[,1:10]
train
head(train)
head(as(train, "list"))
setwd("C:/Users/SURESH/Dropbox/projects/bapm/spring 2016/data mining/project/code")
data <- read.table("ratings100k.csv",)
data <- read.table("ratings100k.csv", col.names = c("user", "item", "rating", "time"))
data <- read.table("ratings100k.csv", col.names = c("user", "item", "rating", "time"), sep = "::")
data <- read.csv("ratings100k.csv")
head(data)
db <- as(data, "realRatingMatrix")
str(db)
movies <- read.csv("movies.csv")
head(movies)
movies$X <- NULL
head(colnames(db))
m <- match(colnames(db), movies$movieId)
movies <- movies[m,]
ilabels <- movies$title
# remove duplicated movies
dup <- which(duplicated(ilabels))
ilabels <- ilabels[-dup]
db <- db[,-dup]
colnames(db) <- ilabels
MovieDB <- db
save(MovieDB, file = "MovieDB.rda")
MovieDB <- read.table("C:/Users/SURESH/Dropbox/projects/bapm/spring 2016/data mining/project/code/MovieDB.rda", quote="\"")
View(MovieDB)
data("MovieDB")
data("MovieDB.rda")
data(MovieDB.rda)
load("MovieDB.rda")
MovieLense100 <- MovieLense[rowCounts(MovieDB)>100,]
MovieLense100 <- MovieDB[rowCounts(MovieDB) > 100, ]
train <- MovieLense[1:100]
train <- MovieLense100[1:100]
rec <- Recommender(train, method = "POPULAR")
rec
pre <- predict(rec, MovieLense100[101:102], n = 10)
pre
as(pre, "list")
pre1 <- predict(rec, MovieLense100[101, 102], type = "ratings")
as(pre1, "matrix")[, 1:10]
setwd("C:/Users/SURESH/Dropbox/projects/bapm/spring 2016/data mining/project/movie_recos")
subset(MovieDB, "Forrest Gump (1994)")
subset(colnames(MovieDB), "Forrest Gump (1994)")
h <- colnames(MovieDB)
head(h)
subset(h, "Forrest Gump (1994)")
subset(h, h=="Forrest Gump (1994)")
which(h == "Forrest Gump (1994)")
userSelect <- matrix(NA, length(h))
row_num <- which(h == "Forrest Gump (1994)")
userSelect[row_num] <- 5
hist(colCounts(MovieDB))
head(colMeans(MovieDB))
class(colMeans(MovieDB))
(colMeans(MovieDB)[1])
ratings < - (colMeans(MovieDB)[])
ratings < - (colMeans(MovieDB))
ratings <- (colMeans(MovieDB))
ratings["Forrest Gump (1994)"]
shiny::runApp()
ls
ls()
runApp()
runApp()
recommender_model <- Recommender(MovieDB, method = "POPULAR")
titles <- colnames(MovieDB)
which(titles == "Forrest Gump (1994)")
recommender_model <- Recommender(MovieDB, method = "POPULAR")
titles <- colnames(MovieDB)
select1 <- "Shawshank Redemption, The (1994)"
select2 <- "Forrest Gump (1994)"
select3 <- "Silence of the Lambs, The (1991)"
row_num <- which(titles == select1)
row_num2 <- which(titles == select2)
row_num3 <- which(titles == select3)
userSelect <- matrix(NA,length(titles))
userSelect[row_num] <- 5 #hard code first selection to rating 5
userSelect[row_num2] <- 4 #hard code second selection to rating 4
userSelect[row_num3] <- 4 #hard code third selection to rating 4
userSelect <- as(userSelect, "realRatingMatrix")
predict(recommender_model, userSelect, n = 10)
recos <- predict(recommender_model, userSelect, n = 10)
as(recos, "list")
userSelect <- MovieDB[100,]
class(userSelect)
userSelect
userSelect[1]
as(userSelect, "list")[1:10]
as(userSelect, "list")[1]
as(userSelect, "list")[1][1]
class(as(userSelect, "list"))
userSelect[,row_num]
as(userSelect[,row_num], "numeric")
as(userSelect[,row_num], "list")
as(userSelect[,row_num2], "list")
as(userSelect[,row_num3], "list")
userSelect <- NA
as(userSelect[,row_num3], "list")
userSelect
userSelect <- MovieDB[100,]
userSelect[1,row_num]
userSelect[1,c(row_num,row_num2, row_num3)]
as(userSelect[1,c(row_num,row_num2, row_num3)], "list")
userSelect[1,-c(row_num,row_num2, row_num3)]
userSelect[1,-c(row_num,row_num2, row_num3)] <- NA
removeKnownRatings(userSelect)
removeKnownRatings(userSelect, userSelect)
as(userSelect[1,c(row_num,row_num2, row_num3)], "list")
userSelect
userSelect <- removeKnownRatings(userSelect, userSelect)
as(userSelect[1,c(row_num,row_num2, row_num3)], "list")
userSelect[1, row_num] <- 5
userSelect <- MovieDB[100,]
mat <- as(userSelect, "matrix")
head(mat)
mat[1,1:5382] <- NA
mat[1,row_num] <-5
mat[1,row_num2] <-4
mat[1,row_num4] <-4
mat[1,row_num3] <-4
userSelect <- as(mat, "realRatingMatrix")
as(userSelect[1,c(row_num,row_num2, row_num3)], "list")
as(userSelect[1,1], "list")
as(userSelect[1,2], "list")
recom <- predict(recommender_model, userSelect, n=10)
as(recom, "list")
nrow(mat)
ncol(mat)
runApp()
runApp()
head(titles[order(titles)])
runApp()
titles <- colnames(MovieDB)
select1 <- "Shawshank Redemption, The (1994)"
select2 <- "Forrest Gump (1994)"
select3 <- "Silence of the Lambs, The (1991)"
row_num <- which(titles == select1)
row_num2 <- which(titles == select2)
row_num3 <- which(titles == select3)
userSelect <- matrix(NA,length(titles))
userSelect[row_num] <- 5 #hard code first selection to rating 5
userSelect[row_num2] <- 4 #hard code second selection to rating 4
userSelect[row_num3] <- 4 #hard code third selection to rating 4
userSelect <- as(userSelect, "realRatingMatrix")
recos <- predict(recommender_model, userSelect, n = 10)
userSelect <- MovieDB[100,]
mat <- as(userSelect, "matrix")
head(mat)
mat[1,1:5382] <- NA
mat[1,row_num] <-5
mat[1,row_num2] <-4
mat[1,row_num4] <-4
mat[1,row_num3] <-4
userSelect <- as(mat, "realRatingMatrix")
as(userSelect[1,c(row_num,row_num2, row_num3)], "list")
as(userSelect[1,1], "list")
as(userSelect[1,2], "list")
recom <- predict(recommender_model, userSelect, n=10)
as(recom, "list")
recom <- predict(recommender_model, userSelect, type="ratings")
as(recom, "list")
as(recom, "list")[1:10]
as(recom, "list")[1][1:10]
head(as(recom, "list"))
